{
  "stats": {
    "vetted": 4,
    "beingBuilt": 0,
    "launched": 0
  },
  "ideas": [
    {
      "id": 4,
      "url": "https://github.com/shivankar-madaan/notbuiltyet/issues/4",
      "title": "Planetary-Scale Land Intelligence Engine — AI-Powered Natural Capital Assessment",
      "category": "Environment",
      "categoryClass": "tag-env",
      "description": {
        "problem": "Countries are under immense pressure to meet \"30x30\" targets (protecting 30% of land by 2030), unlock billions in carbon credits, and hit net-zero...",
        "solution": "A \"Google Maps for Natural Capital\" — an AI platform that ingests every available open data source (satellite imagery, SAR radar, LiDAR, soil...",
        "why": "Intelligence-led planting achieves 80% survival vs 10–20% for random planting — 4x lower CAPEX for the same outcome The platform doesn't plant trees..."
      },
      "fullDescription": {
        "problem": "Countries are under immense pressure to meet \"30x30\" targets (protecting 30% of land by 2030), unlock billions in carbon credits, and hit net-zero commitments — but they have no idea where to start. For any given piece of land, nobody can answer the basic question: \"What is the highest-value ecological intervention here, and what's the ROI?\" Reforestation today is shockingly unintelligent. Organizations plant trees in random locations with 10–20% survival rates, using species poorly matched to soil and climate conditions. Carbon credit projects get funded with no forward-looking climate analysis — trees planted today need to survive in a climate that's 1–2°C warmer with different rainfall patterns by 2050, but almost nobody models this. Urban planners don't know which 500 meters of tree canopy would reduce peak electricity load by megawatts. Insurance companies can't quantify how upstream forest restoration reduces downstream flood claims. The data to answer all of these questions exists — free satellite imagery (Sentinel-2, Landsat), global soil databases (SoilGrids, SSURGO), biodiversity records (GBIF — 2+ billion observations), climate projections (CMIP6), LiDAR terrain data, and dozens more — but it's fragmented across hundreds of institutions, in incompatible formats, and nobody has built the intelligence layer that fuses it all into actionable decisions.",
        "solution": "A \"Google Maps for Natural Capital\" — an AI platform that ingests every available open data source (satellite imagery, SAR radar, LiDAR, soil databases, climate projections, biodiversity records, land ownership, hydrology, air quality) and produces a comprehensive ecological-economic score for every 10m x 10m pixel of land on Earth. The platform runs six core intelligence modules: Land Suitability Scoring — For every pixel: slope, soil depth/pH/drainage, water availability, current land cover, contamination risk, legal status, and critically — forward-looking climate suitability for 2050, not just current conditions. Output: a 0–100 suitability score decomposed into sub-scores. Species Recommendation Engine — Multi-objective optimization that recommends not a single tree but an entire ecological community (canopy species, understory, nitrogen fixers, early colonizers). Species matched to projected 2050 climate envelopes with assisted migration considerations. Uses the TRY Plant Trait Database (12M trait records, 280K species). Ecosystem Services Quantification — The money module. For each site: carbon sequestration trajectory (above-ground, below-ground, soil organic carbon) with monetary value at current credit prices; water services (groundwater recharge in cubic meters, flood risk reduction in avoided damage costs, water quality improvement); biodiversity value (threatened species habitat, corridor connectivity via circuit theory); urban-specific services (cooling in avoided kWh, air quality in health cost savings, stormwater management, property value uplift of 5–15% from mature canopy). Risk Assessment — Fire risk, drought mortality, pest/disease, encroachment probability, political/governance risk, and climate change risk to the planting itself. Produces risk-adjusted ROI — the expected value accounting for probability of failure. Prioritization Engine — Synthesizes everything into ranked opportunities. Clients adjust weighting (water utility weights water, carbon fund weights carbon, city government weights cooling). Specifically flags \"quick wins\": sites where natural regeneration succeeds with just protection, drone seeding is viable, or public land has zero acquisition cost. Monitoring & Verification — Automated satellite-based survival monitoring post-planting, anomaly detection for areas below growth prediction, carbon stock updates, and MRV reports formatted for credit standards (Verra VCS, Gold Standard, ART TREES).",
        "why": "Intelligence-led planting achieves 80% survival vs 10–20% for random planting — 4x lower CAPEX for the same outcome The platform doesn't plant trees — it sells the \"Reforestation Prospectus\" showing governments and corporations exactly where to invest, with verified ROI projections High-quality removal credits trade at $22–$35/tCO2e vs $5–$10 for unverified avoidance credits — the verification layer alone justifies the platform Urban cooling is quantifiable: a single mature tree provides cooling equivalent to 10 room ACs running 20 hours/day. Cities pay for avoided peak grid load After 5 years of monitoring, the longitudinal dataset of what works where becomes the definitive global reference — essentially impossible to replicate Offshore energy, deep sea mining, and infrastructure companies are legally required to do environmental assessments — the compliance automation market alone is massive The 2026 \"ghost forest\" backlash means the market will pay a huge premium for AI-audited proof that planted trees are still alive and sequestering carbon Can start with two people, a laptop, and free satellite data — then scale to serving every government on Earth"
      },
      "improvement": "~4x improvement in tree survival rates (80% vs 10-20%), 90% reduction in site assessment time, ability to quantify ecosystem services (carbon, water, biodiversity, cooling) that are currently unquantified for 99% of land",
      "moats": [
        {
          "name": "Data Moat",
          "cssClass": "moat-data"
        },
        {
          "name": "Technical",
          "cssClass": "moat-technical"
        },
        {
          "name": "Domain Expertise",
          "cssClass": "moat-domain"
        },
        {
          "name": "First Mover",
          "cssClass": "moat-first-mover"
        },
        {
          "name": "Integration Depth",
          "cssClass": "moat-integration"
        }
      ],
      "viability": 82,
      "defensibility": "Very High",
      "votes": 0
    },
    {
      "id": 3,
      "url": "https://github.com/shivankar-madaan/notbuiltyet/issues/3",
      "title": "AI-Powered Deep Sea Species Detection & Environmental Intelligence Platform",
      "category": "Environment",
      "categoryClass": "tag-env",
      "description": {
        "problem": "Deep sea expeditions are expensive — a single ROV dive can cost $50,000–$100,000/day. They generate hours of footage, most of which gets reviewed by...",
        "solution": "A real-time vision model running on the ROV itself (or on the ship) that watches the live feed and does three things: Matches known species against a...",
        "why": "Whoever partners with NOAA, Schmidt Ocean Institute, or Woods Hole gets a continuous stream of labeled footage nobody else has — every dive makes the..."
      },
      "fullDescription": {
        "problem": "Deep sea expeditions are expensive — a single ROV dive can cost $50,000–$100,000/day. They generate hours of footage, most of which gets reviewed by 1–2 marine biologists months or years later. Novel species get spotted, logged in a spreadsheet, and wait years for a taxonomist to officially describe them. Some never get followed up on at all. The ocean below 200m is so poorly explored that scientists estimate we've formally described maybe 10–20% of species living there. Deep sea footage is brutal to work with — poor lighting, particles in the water, motion blur, creatures that are semi-transparent or bioluminescent, extreme similarity between related species. Current marine biology databases like OBIS or WoRMS have records but very few standardized images at depth. Training data is genuinely scarce and fragmented across dozens of institutions who don't share well.",
        "solution": "A real-time vision model running on the ROV itself (or on the ship) that watches the live feed and does three things: Matches known species against a database of deep sea life with high confidence Flags anomalies — things that don't match anything in the database, ranked by how unusual they are Alerts the operator mid-dive so they can slow down, reposition, collect a sample, or get a better angle before the creature disappears forever The key insight is that the window to investigate is the dive itself. By the time a human reviews footage back on land, the moment is gone. The \"unknown\" detection problem is harder than standard classification — you're not just asking \"what is this?\" but \"is this something we've never seen?\" That requires anomaly detection, not just a classifier, which is a harder ML problem. The real business pivot: don't just sell species identification — sell Environmental Intelligence. Offshore wind and oil/gas companies are legally required to do biodiversity assessments before they can drill or build. They have infinite money and hate waiting for manual footage review. Automate their compliance reports and you have a scalable B2B business. As deep sea mining kicks off, environmental impact monitoring will be a multi-billion dollar mandate. The one-sentence pitch: \"We automate the environmental permitting bottleneck for offshore energy — what currently takes 6 months of manual footage review takes us 48 hours, and our reports are defensible in court.\"",
        "why": "Whoever partners with NOAA, Schmidt Ocean Institute, or Woods Hole gets a continuous stream of labeled footage nobody else has — every dive makes the model better, creating an essentially irreplicable data moat after 5 years Offshore wind alone is projected to be a $1T industry by 2040 — every single installation requires an Environmental Impact Assessment currently done by expensive manual contractors Deep sea organisms are a massive source of novel compounds for pharma — being the \"Google Search for Deep Sea Biology\" makes you the ultimate gatekeeper for bio-prospecting The US Navy has enormous interest in understanding biological activity for distinguishing whale sounds from submarine signatures — a DoD contract changes the entire funding trajectory Grows into: citizen science layer on recreational dive footage, passive monitoring buoys, environmental DNA cross-referencing, and eventually a living, continuously updated atlas of ocean biodiversity"
      },
      "improvement": "~90% reduction in footage review time for environmental compliance, real-time anomaly detection vs months-delayed manual review",
      "moats": [
        {
          "name": "Data Moat",
          "cssClass": "moat-data"
        },
        {
          "name": "Technical",
          "cssClass": "moat-technical"
        },
        {
          "name": "Domain Expertise",
          "cssClass": "moat-domain"
        },
        {
          "name": "First Mover",
          "cssClass": "moat-first-mover"
        }
      ],
      "viability": 62,
      "defensibility": "High",
      "votes": 0
    },
    {
      "id": 2,
      "url": "https://github.com/shivankar-madaan/notbuiltyet/issues/2",
      "title": "AI-Powered Asteroid Prospecting Platform — Composition Intelligence from Public Survey Data",
      "category": "Other",
      "categoryClass": "tag-other",
      "description": {
        "problem": "The asteroid mining industry is emerging fast — multiple startups are racing to extract resources from near-Earth asteroids. But they all face the...",
        "solution": "An AI-native asteroid prospecting platform that fuses public data from NASA (NeoWs, JPL SBDB), ESA, JAXA, GAIA spacecraft, and ground-based surveys...",
        "why": "Asteroid resources represent a multi-trillion dollar frontier — a single metallic asteroid can contain more platinum-group metals than ever mined on..."
      },
      "fullDescription": {
        "problem": "The asteroid mining industry is emerging fast — multiple startups are racing to extract resources from near-Earth asteroids. But they all face the same bottleneck: we know where asteroids are (NASA tracks 30,000+ NEOs), but we barely know what they're made of. Spectral data exists for only a fraction of known asteroids, and even when it does, going from \"S-type classification\" to \"estimated platinum content\" is unreliable. The best public tool for this was built in 2012 with naive heuristics and appears unmaintained. Composition prediction from sparse spectral data remains a hard, unsolved problem — current ML models only achieve ~92% accuracy on broad taxonomic groups and routinely confuse critical categories (C-type vs X-type). Mining companies are making multi-million dollar mission decisions with terrible geological intelligence.",
        "solution": "An AI-native asteroid prospecting platform that fuses public data from NASA (NeoWs, JPL SBDB), ESA, JAXA, GAIA spacecraft, and ground-based surveys to build the most comprehensive composition intelligence layer for asteroids. Modern ML models trained on meteorite spectra, orbital family membership, albedo, and multi-parameter constraints to predict composition where spectral data is sparse or missing. Each asteroid gets an economic viability score combining estimated resource value, delta-v accessibility, launch window frequency, rotation rate, and size. Real-time updates as new survey data arrives. Essentially the Bloomberg Terminal for asteroid mining — the intelligence layer that every mining company needs but none are building as a standalone product.",
        "why": "Asteroid resources represent a multi-trillion dollar frontier — a single metallic asteroid can contain more platinum-group metals than ever mined on Earth. But this industry can't scale on guesswork. The companies launching missions need reliable geological intelligence the same way terrestrial mining companies rely on geological surveys before drilling. By making this intelligence accessible, this platform accelerates the entire space mining industry, lowers the cost of bad bets, and helps humanity access the resources needed for long-term civilizational growth beyond Earth. The data is already public and free — the AI interpretation layer is what's missing."
      },
      "improvement": "~10-100x better composition prediction coverage vs current public tools (existing tools cover 600K asteroids with rough heuristics; modern ML can provide probabilistic composition estimates for all 30K+ NEOs with confidence scores)",
      "moats": [
        {
          "name": "Data Moat",
          "cssClass": "moat-data"
        },
        {
          "name": "Technical",
          "cssClass": "moat-technical"
        },
        {
          "name": "Domain Expertise",
          "cssClass": "moat-domain"
        },
        {
          "name": "First Mover",
          "cssClass": "moat-first-mover"
        }
      ],
      "viability": 62,
      "defensibility": "High",
      "votes": 0
    },
    {
      "id": 1,
      "url": "https://github.com/shivankar-madaan/notbuiltyet/issues/1",
      "title": "AI-Powered Construction Site Progress Monitoring Platform",
      "category": "Infrastructure",
      "categoryClass": "tag-infra",
      "description": {
        "problem": "Construction is one of the least digitized industries in the world, and it shows. Projects routinely run over budget and behind schedule — globally,...",
        "solution": "A platform that uses drone and satellite imagery combined with computer vision to automatically monitor construction sites — turning raw visual data...",
        "why": "Makes construction safer by catching safety violations in near real-time instead of after an accident Makes public infrastructure projects..."
      },
      "fullDescription": {
        "problem": "Construction is one of the least digitized industries in the world, and it shows. Projects routinely run over budget and behind schedule — globally, large construction projects average 80% over budget and 20 months behind schedule. The consequences ripple through society: Wasted resources: Delays and rework waste materials, energy, and human labor on a massive scale Safety failures: Construction remains one of the most dangerous industries. Poor site monitoring means safety violations (missing PPE, improper scaffolding, unsecured zones) go undetected until someone gets hurt Accountability gaps: Progress is tracked through subjective site visits and inconsistent photo documentation — there's no reliable, quantifiable way to know if a project is on track Infrastructure bottlenecks: Hospitals, schools, housing, and public infrastructure projects get delayed for years, directly impacting the communities waiting for them Fraud and misreporting: Without verifiable progress data, misrepresentation of construction status is difficult to detect — affecting public projects and aid-funded developments in particular",
        "solution": "A platform that uses drone and satellite imagery combined with computer vision to automatically monitor construction sites — turning raw visual data into objective, quantifiable progress metrics. How It Works: Data Collection — Drones capture high-resolution aerial footage on a regular schedule. Freely available satellite imagery (Sentinel-2, Landsat) supplements with continuous coverage AI Analysis — Computer vision models detect and quantify structural progress (foundation, floors, walls), material stockpiles, equipment activity, and critically — safety violations like missing barriers or workers without protective equipment Transparency & Alerts — Automated reports with visual before/after comparisons, real-time dashboards showing objective completion metrics, and immediate alerts when progress deviates from plan or safety issues are detected",
        "why": "Makes construction safer by catching safety violations in near real-time instead of after an accident Makes public infrastructure projects accountable with verifiable, objective progress data Reduces waste by catching deviations early when course-correction is still cheap Enables transparency for aid-funded and government projects where misreporting is a real problem Helps close the infrastructure gap in developing regions by making project oversight scalable and affordable"
      },
      "improvement": "~70% reduction in manual inspection overhead, 3-5x faster deviation and safety violation detection",
      "moats": [
        {
          "name": "Data Moat",
          "cssClass": "moat-data"
        },
        {
          "name": "Technical",
          "cssClass": "moat-technical"
        },
        {
          "name": "Domain Expertise",
          "cssClass": "moat-domain"
        },
        {
          "name": "First Mover",
          "cssClass": "moat-first-mover"
        },
        {
          "name": "Integration Depth",
          "cssClass": "moat-integration"
        }
      ],
      "viability": 82,
      "defensibility": "High",
      "votes": 0
    }
  ]
}
